<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>时光小栈</title>
    <link>/ai/math/</link>
    <description>Recent content on 时光小栈</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-Hans</language>
    <managingEditor>rinetd@163.com (rinetd)</managingEditor>
    <webMaster>rinetd@163.com (rinetd)</webMaster>
    <copyright>Copyright (c) 2017. All rights reserved. (版权所有) &lt;a href=&#39;http://www.miitbeian.gov.cn/&#39;&gt;鲁ICP备17074587号-1&lt;/a&gt;</copyright>
    <lastBuildDate>Sat, 09 Mar 2019 08:48:13 +0800</lastBuildDate>
    
	<atom:link href="/ai/math/feed.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>leetecode</title>
      <link>/math/leetecode/</link>
      <pubDate>Sat, 09 Mar 2019 08:48:13 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/leetecode/</guid>
      <description>4. 寻找两个有序数组的中位数 给定两个大小为 m 和 n 的有序数组 nums1 和 nums2 ,请你找出这两个有序数组的中位数. 并且要求算法的时间复杂度为 O(log(m + n))。你可以</description>
    </item>
    
    <item>
      <title>scikit_learn</title>
      <link>/math/scikit/scikit_learn/</link>
      <pubDate>Wed, 27 Feb 2019 22:01:39 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/scikit/scikit_learn/</guid>
      <description>第一章 模型预处理 · Scikit-learn 秘籍</description>
    </item>
    
    <item>
      <title>参数方程</title>
      <link>/math/%E5%8F%82%E6%95%B0%E6%96%B9%E7%A8%8B/</link>
      <pubDate>Fri, 25 Jan 2019 11:27:12 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/%E5%8F%82%E6%95%B0%E6%96%B9%E7%A8%8B/</guid>
      <description>高中数学要求知识点：坐标系与参数方程 - 知乎 参数方程与普通方程的区别 普通方程 直接给出曲线上的点(x,y)之间的关系 参数方程 引入第三个参数t间接</description>
    </item>
    
    <item>
      <title>圆锥曲线硬解定理</title>
      <link>/math/%E5%9C%86%E9%94%A5%E6%9B%B2%E7%BA%BF%E7%A1%AC%E8%A7%A3%E5%AE%9A%E7%90%86/</link>
      <pubDate>Fri, 25 Jan 2019 11:27:12 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/%E5%9C%86%E9%94%A5%E6%9B%B2%E7%BA%BF%E7%A1%AC%E8%A7%A3%E5%AE%9A%E7%90%86/</guid>
      <description>【解析几何】暴力之美：圆锥曲线硬解定理 - 知乎</description>
    </item>
    
    <item>
      <title>sort compose</title>
      <link>/math/%E6%8E%92%E5%88%97%E7%BB%84%E5%90%88/sort-compose/</link>
      <pubDate>Fri, 25 Jan 2019 09:06:21 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/%E6%8E%92%E5%88%97%E7%BB%84%E5%90%88/sort-compose/</guid>
      <description>组合 --&amp;gt;有次序之后--&amp;gt;就是排列 排列与元素的顺序有关，组合与顺序无关． 两种方法(思想) 我们一定先要思考是分类完成任务，还是分步</description>
    </item>
    
    <item>
      <title>label</title>
      <link>/math/scikit/label/</link>
      <pubDate>Fri, 18 Jan 2019 16:05:00 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/scikit/label/</guid>
      <description>Multiclass classification 多类分类： 意味着一个分类任务需要对多于两个类的数据进行分类。比如，对一系列的橘子，苹果或者梨的图片进行分类。多类分类假设每一个样本有且仅</description>
    </item>
    
    <item>
      <title>multi</title>
      <link>/math/scikit/multi/</link>
      <pubDate>Fri, 18 Jan 2019 16:05:00 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/scikit/multi/</guid>
      <description>Multiclass classification 多类分类： 意味着一个分类任务需要对多于两个类的数据进行分类。比如，对一系列的橘子，苹果或者梨的图片进行分类。多类分类假设每一个样本有且仅</description>
    </item>
    
    <item>
      <title>牛顿迭代法求近似值Newton&#39;s method</title>
      <link>/math/newton/</link>
      <pubDate>Fri, 14 Dec 2018 09:05:42 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/newton/</guid>
      <description>如何不依靠计算器和数学用表，手动给非平方数开根号？ - 知乎 牛顿迭代法求解平方根 - YoungGy的专栏 - CSDN博客 牛顿迭代法(Newton&#39;s</description>
    </item>
    
    <item>
      <title>红黑树和B树应用场景</title>
      <link>/math/algorithm/rbtree/</link>
      <pubDate>Mon, 19 Nov 2018 14:49:44 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/algorithm/rbtree/</guid>
      <description>红黑树和B树应用场景有何不同？ 2者都是有序数据结构，可用作数据容器。 红黑树多用在内部排序，即全放在内存中的，微软STL的map和set的内部</description>
    </item>
    
    <item>
      <title>math as code</title>
      <link>/math/math-as-code/</link>
      <pubDate>Sat, 17 Nov 2018 14:05:18 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/math-as-code/</guid>
      <description>math-as-code 译注：译者英文与数学水平都非常有限，尝试翻译，如有错误请指正。英文原版 在此。 这是一份通过对比数学符号和JavaScript代码来帮助开发者</description>
    </item>
    
    <item>
      <title>keras layer</title>
      <link>/math/keras-layer/</link>
      <pubDate>Sat, 17 Nov 2018 11:51:57 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/math/keras-layer/</guid>
      <description>BatchNormalization layer: 通常在线性向非线性转变时使用,如下： model.add(Dense(100,input_dim=20)) model.add(BatchNormalization()) model.add(Activation(&#39;relu&#39;)) 作用： 能够保证权重的尺度不变，因为BatchNormalization在激活函数前对输入进行了</description>
    </item>
    
    <item>
      <title>Derivative 导数</title>
      <link>/ai/math/gaoshu-derivative/</link>
      <pubDate>Tue, 15 May 2018 10:25:47 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/gaoshu-derivative/</guid>
      <description>隐函数求导 ===方法一=== *把n元隐函数看作(n+1)元函数，通过[[多元函数]]的[[偏导数]]的商求得n元隐函数的导数。 ====示例=</description>
    </item>
    
    <item>
      <title>均值不等式</title>
      <link>/ai/math/%E5%9D%87%E5%80%BC%E4%B8%8D%E7%AD%89%E5%BC%8F/</link>
      <pubDate>Tue, 15 May 2018 10:25:47 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/%E5%9D%87%E5%80%BC%E4%B8%8D%E7%AD%89%E5%BC%8F/</guid>
      <description>均值不等式及其积分形式 平均而言，你用的是错误的平均数（上）：几何平均数和调和平均数人工智能_机器人之家 均值不等式及其积分形式 摘要：本文将给出</description>
    </item>
    
    <item>
      <title>平面方程</title>
      <link>/ai/math/02%E5%B9%B3%E9%9D%A2%E6%96%B9%E7%A8%8B/</link>
      <pubDate>Tue, 15 May 2018 10:25:47 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/02%E5%B9%B3%E9%9D%A2%E6%96%B9%E7%A8%8B/</guid>
      <description>任何一个x,y,z的一次方程的图形是平面；反之，任何一个平面的方程是x,y,z的一次方程。Ax+By+Cz+D=0(A,B,C不同时为0)，</description>
    </item>
    
    <item>
      <title>方差和协方差</title>
      <link>/ai/math/%E6%A6%82%E7%8E%87/math_variance_covariance%E6%96%B9%E5%B7%AE%E5%92%8C%E5%8D%8F%E6%96%B9%E5%B7%AE/</link>
      <pubDate>Tue, 15 May 2018 10:25:47 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/%E6%A6%82%E7%8E%87/math_variance_covariance%E6%96%B9%E5%B7%AE%E5%92%8C%E5%8D%8F%E6%96%B9%E5%B7%AE/</guid>
      <description>方差和协方差</description>
    </item>
    
    <item>
      <title>法向量</title>
      <link>/ai/math/03%E6%B3%95%E5%90%91%E9%87%8F/</link>
      <pubDate>Tue, 15 May 2018 10:25:47 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/03%E6%B3%95%E5%90%91%E9%87%8F/</guid>
      <description>直线的法向量与平行垂直直线系 | Math173 叉乘法: 向量并排写两遍，掐头去尾留中间，交叉相乘再作差 初中时，我们接触的直线方程为y=kx+b的形式，而在</description>
    </item>
    
    <item>
      <title>点到直线方程的距离</title>
      <link>/ai/math/01%E7%82%B9%E5%88%B0%E7%9B%B4%E7%BA%BF%E6%96%B9%E7%A8%8B%E7%9A%84%E8%B7%9D%E7%A6%BB/</link>
      <pubDate>Tue, 15 May 2018 10:25:47 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/01%E7%82%B9%E5%88%B0%E7%9B%B4%E7%BA%BF%E6%96%B9%E7%A8%8B%E7%9A%84%E8%B7%9D%E7%A6%BB/</guid>
      <description>结论: d=|Ax0+By0+C|/√(A²+B²) 思路1: 叉积法 向量的叉乘 用叉乘来计算更好。向量a和向量b的差乘的模等于它们所张开的平行四边</description>
    </item>
    
    <item>
      <title>盘点数学里十大不需要语言的证明</title>
      <link>/ai/math/%E6%97%A0%E5%AD%97%E8%AF%81%E6%98%8E/</link>
      <pubDate>Tue, 15 May 2018 10:25:47 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/%E6%97%A0%E5%AD%97%E8%AF%81%E6%98%8E/</guid>
      <description>盘点数学里十大不需要语言的证明 | 科学人 | 果壳网 科技有意思</description>
    </item>
    
    <item>
      <title>直线方程</title>
      <link>/ai/math/01%E7%9B%B4%E7%BA%BF%E6%96%B9%E7%A8%8B/</link>
      <pubDate>Tue, 15 May 2018 10:25:47 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/01%E7%9B%B4%E7%BA%BF%E6%96%B9%E7%A8%8B/</guid>
      <description>直线方程 直线方程的公式有以下几种： 点斜式（用于已知斜率和一点坐标） $y-y_0=f&#39;(x)(x-x_0)$ 斜截式（用于已知斜率和y轴截距）点斜式的简化版,已知点(0,b)正好在y</description>
    </item>
    
    <item>
      <title>Planar Equation 平面方程</title>
      <link>/ai/math/02%E5%B9%B3%E9%9D%A2%E6%96%B9%E7%A8%8Bplanar-equation/</link>
      <pubDate>Fri, 11 May 2018 15:01:41 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/02%E5%B9%B3%E9%9D%A2%E6%96%B9%E7%A8%8Bplanar-equation/</guid>
      <description>导数和梯度，切线和法向量 - CSDN博客 先求参数方程 根据参数方程求解 法向量 切线方程 法平面方程 切线方程: 点斜率式 $y-y_0 = f&#39;(x)(x-x_0)$ 法线方程: $y-y_0 = - \frac{1}{f&#39;(x)}(x-x_0)$ == 由一点</description>
    </item>
    
    <item>
      <title>Machine Learning机器学习</title>
      <link>/ai/math/machine-learning/</link>
      <pubDate>Wed, 02 May 2018 13:41:50 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/machine-learning/</guid>
      <description>机器学习评估指标的前世今生 - 知乎 gitbooks · Python机器学习 机器学习常见算法分类汇总 27 个机器学习的小抄 scutan90/DeepLearning-500-questions: 深度学习500问，以问答形式对常用的概率</description>
    </item>
    
    <item>
      <title>Gradient Descent</title>
      <link>/ai/math/gradient-descent/</link>
      <pubDate>Thu, 26 Apr 2018 16:52:04 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/gradient-descent/</guid>
      <description>CS231n课程笔记翻译：反向传播笔记 - 知乎 机器学习概念：梯度下降 学习梯度，需要一定的数学知识：导数（Derivative）、偏导数（Par</description>
    </item>
    
    <item>
      <title>线性代数Linear</title>
      <link>/ai/math/math-base-linear/</link>
      <pubDate>Thu, 19 Apr 2018 08:45:45 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/math-base-linear/</guid>
      <description>「Deep Learning」读书系列分享第二章：线性代数 | 分享总结 | 雷锋网 标量(scalar) i 0阶张量 一个标量，一个单独的数。其他大部分对</description>
    </item>
    
    <item>
      <title>泰勒公式-Taylor</title>
      <link>/ai/math/taylor/</link>
      <pubDate>Wed, 18 Apr 2018 16:57:04 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/taylor/</guid>
      <description>转 如何通俗地解释泰勒公式？ 泰勒的意义: 任意一点的f(x)的值都可以在以往的任意一点展开得到. 泰勒展开 给予了我们预知未来的能力,或者说让我们拥</description>
    </item>
    
    <item>
      <title>Latex 基础</title>
      <link>/ai/math/latex/</link>
      <pubDate>Wed, 18 Apr 2018 16:33:04 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/latex/</guid>
      <description>一份其实很短的 LaTeX 入门文档 | 始终 用于数学、科学和工程的希腊字母 - 维基百科，自由的百科全书 Latex数学符号表 Katex实例 LaTeX —— 特殊符号与数学</description>
    </item>
    
    <item>
      <title>机器学习必过的坎-梯度</title>
      <link>/ai/math/gradient/</link>
      <pubDate>Tue, 17 Apr 2018 10:20:25 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/gradient/</guid>
      <description>CS231n课程笔记翻译：反向传播笔记 - 知乎 梯度 偏导数 方向导数 多元函数的 切向量和法向量 切平面方程 法线方程 （F&#39;x，F&#39;y，F&#39;z）是曲线的法</description>
    </item>
    
    <item>
      <title>似然与极大似然估计</title>
      <link>/ai/math/likelihood/</link>
      <pubDate>Tue, 17 Apr 2018 10:05:05 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/likelihood/</guid>
      <description>似然与极大似然估计 [ 似然与概率 在统计学中，似然函数（likelihood function，通常简写为likelihood，似然）是一个非常重</description>
    </item>
    
    <item>
      <title>贝叶斯定理</title>
      <link>/ai/math/bayes/</link>
      <pubDate>Tue, 17 Apr 2018 10:05:05 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/bayes/</guid>
      <description>条件概率与贝叶斯定理 - 知乎 Think Bayes - 我所理解的贝叶斯定理 MLE MAP 频率学派 - Frequentist - Maximum Likelihood Estimation (MLE，最大似然估计) 贝叶斯学派 - Bayesian - Maximum A Posteriori (MAP，最大后验</description>
    </item>
    
    <item>
      <title>Euler计划</title>
      <link>/ai/math/gaoshu-euler/</link>
      <pubDate>Mon, 02 Apr 2018 18:18:59 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/gaoshu-euler/</guid>
      <description>欧拉计划中文版 线性筛法（欧拉筛） 筛法小结 (Eratosthenes/Euler)</description>
    </item>
    
    <item>
      <title>Quicksort</title>
      <link>/ai/math/algorithm/quicksort/</link>
      <pubDate>Sat, 31 Mar 2018 18:03:15 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/algorithm/quicksort/</guid>
      <description>动画展示 1）在数据集之中，选择一个元素作为&amp;quot;基准&amp;quot; pivot 2）所有小于&amp;quot;基准&amp;quot;的元素，都移到&amp;quot;基</description>
    </item>
    
    <item>
      <title>Sort Algorithms排序算法基础详解</title>
      <link>/ai/math/algorithm/sort/</link>
      <pubDate>Sat, 31 Mar 2018 17:44:39 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/algorithm/sort/</guid>
      <description>聊聊4种主流排序算法(番外篇):快速排序的优化历程 - 许炎的个人博客 十大经典排序算法（动图演示） - 一像素 - 博客园 https://github.com/fabioberger/sort Algorithms Reviewing algorithms, learning go. Images from wikipedia. Search Binary Search 0.3 相关</description>
    </item>
    
    <item>
      <title>三角函数</title>
      <link>/ai/math/%E4%B8%89%E8%A7%92%E5%87%BD%E6%95%B0/</link>
      <pubDate>Sat, 01 Apr 2017 04:15:26 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/%E4%B8%89%E8%A7%92%E5%87%BD%E6%95%B0/</guid>
      <description>可能是最好的讲解双曲函数的文章 - 知乎 正加正在前 正减正后迁 余余一色余 余差反了天 零、写在前面 这只是闲着没事随便写着玩的，大家随便看看就行。 一、基</description>
    </item>
    
    <item>
      <title>HMAC 算法</title>
      <link>/ai/math/algorithm/hmac%E7%AE%97%E6%B3%95/</link>
      <pubDate>Tue, 29 Mar 2016 21:25:45 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/algorithm/hmac%E7%AE%97%E6%B3%95/</guid>
      <description>《NodeJS开发教程14-Crypto加密与解密》 - 简书 HMAC: 就是带个密码(key)也叫salt的hash算法, key 是发送方和接收方都有的 hmac = md5(message</description>
    </item>
    
    <item>
      <title>冒泡排序</title>
      <link>/ai/math/algorithm/bubblesort/</link>
      <pubDate>Tue, 29 Mar 2016 21:25:45 +0800</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/algorithm/bubblesort/</guid>
      <description>冒泡排序 动画效果 冒泡排序是一种交换排序，它的基本思想是：两两比较相邻记录的关键字，如果反序则交换，知道没有反序的记录为止。冒泡的实现上有很多</description>
    </item>
    
    <item>
      <title></title>
      <link>/ai/math/%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%9C%AC%E8%B4%A8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/ai/math/%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%9C%AC%E8%B4%A8/</guid>
      <description>学习的本质就是重复,并非不停的重复,而是不停的验证规律,但有的真就是在重复.
重复的过程不是记忆,而是寻找问题和答案之间规律.
知识 = 通过学习来压缩信息 (精华的东西)
当真正学会的时候,例子就会被压缩成知识.
从小到大 叫 抽象能力
从大到小 叫 提炼</description>
    </item>
    
  </channel>
</rss>