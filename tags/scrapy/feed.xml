<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>scrapy on 时光小栈</title>
    <link>/tags/scrapy/</link>
    <description>Recent content in scrapy on 时光小栈</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-Hans</language>
    <managingEditor>rinetd@163.com (rinetd)</managingEditor>
    <webMaster>rinetd@163.com (rinetd)</webMaster>
    <copyright>Copyright (c) 2017. All rights reserved. (版权所有) &lt;a href=&#39;http://www.miitbeian.gov.cn/&#39;&gt;鲁ICP备17074587号-1&lt;/a&gt;</copyright>
    <lastBuildDate>Thu, 13 Feb 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/scrapy/feed.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Scrapy研究探索（七）如何防止被ban之策略大集合</title>
      <link>/language/python/scrapy/scrapy%E7%A0%94%E7%A9%B6%E6%8E%A2%E7%B4%A2%E4%B8%83%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E8%A2%ABban%E4%B9%8B%E7%AD%96%E7%95%A5%E5%A4%A7%E9%9B%86%E5%90%88/</link>
      <pubDate>Thu, 13 Feb 2014 00:00:00 +0000</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/language/python/scrapy/scrapy%E7%A0%94%E7%A9%B6%E6%8E%A2%E7%B4%A2%E4%B8%83%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2%E8%A2%ABban%E4%B9%8B%E7%AD%96%E7%95%A5%E5%A4%A7%E9%9B%86%E5%90%88/</guid>
      <description>话说在尝试设置download_delay小于1，并且无任何其他防止被ban的策略之后，我终于成功的被ban了。 关于scrapy的使用可参见</description>
    </item>
    
    <item>
      <title>scrapy Items</title>
      <link>/language/python/scrapy/scrapy-items/</link>
      <pubDate>Thu, 13 Feb 2014 00:00:00 +0000</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/language/python/scrapy/scrapy-items/</guid>
      <description>原文地址：http://doc.scrapy.org/en/latest/topics/items.html 爬取网页最主要的目的就是从非结构</description>
    </item>
    
    <item>
      <title>scrapy Link Extractors</title>
      <link>/language/python/scrapy/scrapy-link-extractors/</link>
      <pubDate>Thu, 13 Feb 2014 00:00:00 +0000</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/language/python/scrapy/scrapy-link-extractors/</guid>
      <description>原文地址：http://doc.scrapy.org/en/latest/topics/link-extractors.html LinkExtractors 对象唯一的</description>
    </item>
    
    <item>
      <title>scrapy Selectors</title>
      <link>/language/python/scrapy/scrapy-selectors/</link>
      <pubDate>Thu, 13 Feb 2014 00:00:00 +0000</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/language/python/scrapy/scrapy-selectors/</guid>
      <description>原文地址：http://doc.scrapy.org/en/latest/topics/selectors.html 在爬取网页的过程中最常见</description>
    </item>
    
    <item>
      <title>scrapy Spiders</title>
      <link>/language/python/scrapy/scrapy-spiders/</link>
      <pubDate>Thu, 13 Feb 2014 00:00:00 +0000</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/language/python/scrapy/scrapy-spiders/</guid>
      <description>原文地址：http://doc.scrapy.org/en/latest/topics/spiders.html 蜘蛛爬行过程大体如下： 以给起</description>
    </item>
    
    <item>
      <title>scrapy 命令行工具</title>
      <link>/language/python/scrapy/scrapy-command-line-tool/</link>
      <pubDate>Thu, 13 Feb 2014 00:00:00 +0000</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/language/python/scrapy/scrapy-command-line-tool/</guid>
      <description>原文地址：http://doc.scrapy.org/en/latest/topics/commands.html scrapy 通过command-li</description>
    </item>
    
    <item>
      <title>scrapy 安装</title>
      <link>/language/python/scrapy/scrapy-installation/</link>
      <pubDate>Thu, 13 Feb 2014 00:00:00 +0000</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/language/python/scrapy/scrapy-installation/</guid>
      <description>原文地址：http://doc.scrapy.org/en/latest/intro/install.html ##准备工作 python 2.7 python --version lxml 安装指南</description>
    </item>
    
    <item>
      <title>scrapy 导读</title>
      <link>/language/python/scrapy/scrapy-tutorial/</link>
      <pubDate>Thu, 13 Feb 2014 00:00:00 +0000</pubDate>
      <author>rinetd@163.com (rinetd)</author>
      <guid>/language/python/scrapy/scrapy-tutorial/</guid>
      <description>原文地址：http://doc.scrapy.org/en/latest/intro/tutorial.html ##Scrapy 一瞥 定义你想要抓取的数据模</description>
    </item>
    
  </channel>
</rss>